{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI not available. Running in serial.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/common/software/m2650/python-cori/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# sys.path.insert(0,'/global/homes/b/bpb/metaiq/')\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/pactolus/')\n",
    "import score_frag_dag as sfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = '/scratch2/scratchdirs/bpb/level_3_trees/'\n",
    "# path = '/project/projectdirs/metatlas/projects/clean_pactolus_trees/'\n",
    "path = '/projectb/sandbox/metatlas/projects/clean_pactolus_trees/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path = '/project/projectdirs/openmsi/projects/ben_trees/'\n",
    "sfg = reload(sfg)\n",
    "tree_file = sfg.make_file_lookup_table_by_MS1_mass(path=path)\n",
    "np.save(os.path.join(path,'tree_lookup.npy'),tree_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.path.join(os.path.join(path,'tree_lookup.npy'))\n",
    "%ls -lt $temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5py\n",
    "\n",
    "trees = np.load('/projectb/sandbox/metatlas/projects/clean_pactolus_trees/tree_lookup.npy')\n",
    "\n",
    "counter = 0\n",
    "bad_files = []\n",
    "for f in trees['filename']:\n",
    "    with h5py.File(f,'r+') as file_reader:\n",
    "        for inchi_key in file_reader.keys():\n",
    "            for depth_key in file_reader[inchi_key].keys():\n",
    "                if not 'max_depth=' in depth_key:\n",
    "                    counter += 1\n",
    "                    bad_files.append(f)\n",
    "#                     print(f)\n",
    "#                     print(inchi_key,depth_key)\n",
    "#                     tree = file_reader[inchi_key][depth_key][:]\n",
    "#                     print('')\n",
    "\n",
    "print(counter)\n",
    "\n",
    "with open('/global/homes/b/bpb/Downloads/bad_files.txt','w') as fid:\n",
    "    fid.write('\\n'.join(bad_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = tree_file[-2][0]\n",
    "with sfg.h5py.File(filename,'r') as file_reader:\n",
    "    group_key = file_reader.keys()[0]\n",
    "    data_key = file_reader[group_key].keys()[0]\n",
    "    tree = file_reader[group_key][data_key][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t2 = np.load(os.path.join(path,'tree_lookup.npy'))\n",
    "df = pd.DataFrame(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['inchi_key'] = df.filename.apply(lambda x: x.split('_')[-1].replace('.h5',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_ema_idx = []\n",
    "ema_df = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_pos_hilic_atlas_50447.pkl')\n",
    "missing_inchi_key = []\n",
    "for i,row in ema_df.iterrows():\n",
    "    if df[df.inchi_key == row.inchi_key].shape[0] == 0:\n",
    "        missing_ema_idx.append(i)\n",
    "        missing_inchi_key.append(row.inchi_key)\n",
    "        \n",
    "print len(missing_ema_idx)\n",
    "ema_df = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_neg_hilic_atlas_50447.pkl')\n",
    "\n",
    "for i,row in ema_df.iterrows():\n",
    "    if df[df.inchi_key == row.inchi_key].shape[0] == 0:\n",
    "        if not row.inchi_key in missing_inchi:\n",
    "            missing_ema_idx.append(i)\n",
    "            missing_inchi_key.append(row.inchi_key)\n",
    "        \n",
    "print len(missing_ema_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/global/homes/b/bpb/metatlas/')\n",
    "from metatlas.compounds import structure_cleaning as mol_clean\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delete_list = []\n",
    "# delete_list.append(df[df.ms1_mass == -1]['filename'].tolist())\n",
    "# print(len(delete_list[0]))\n",
    "# trim_df = df[df['ms1_mass']>0].copy()\n",
    "\n",
    "# delete_list.append(trim_df[~trim_df.isin(df_dedup).all(1)]['filename'].tolist())\n",
    "# print(len(delete_list[0])),(len(delete_list[1]))\n",
    "# delete_list = [aa for a in delete_list for aa in a]\n",
    "# len(delete_list)\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    if row.inchi and row.ms1_mass > 100:\n",
    "        mol = Chem.MolFromInchi(row.inchi)\n",
    "        try:\n",
    "            (new_mol,is_neutral) = mol_clean.NeutraliseCharges(mol)\n",
    "            if row.inchi != Chem.MolToInchi(new_mol):\n",
    "                delete_list.append(i)\n",
    "        except:\n",
    "            delete_list.append(i)\n",
    "            print row.inchi\n",
    "    else:\n",
    "        delete_list.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_junk = df.loc[delete_list]\n",
    "trim_df = df.copy()\n",
    "trim_df = trim_df[~df.isin(df_junk).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trim_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trim_df.sort_values(['max_depth'],ascending=False,inplace=True)\n",
    "df_dedup = trim_df.drop_duplicates(subset=['inchi_key'])\n",
    "df_dedup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# indir = '/project/projectdirs/metatlas/projects/pactolus_trees/'\n",
    "# outdir = '/project/projectdirs/metatlas/projects/clean_pactolus_trees/'\n",
    "# keep_files = []\n",
    "# for i,row in df_dedup.iterrows():\n",
    "#     keep_files.append(os.path.basename(row.filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# out_str = 'cp %s{%s} %s'%(indir,','.join(keep_files),outdir)\n",
    "# with open('/global/u2/b/bpb/copy_files.sh','w') as fid:\n",
    "#     fid.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_ema_idx = []\n",
    "ema_df = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_pos_hilic_atlas_50447.pkl')\n",
    "missing_inchi_key = []\n",
    "for i,row in ema_df.iterrows():\n",
    "    if df_dedup[df_dedup.inchi_key == row.inchi_key].shape[0] == 0:\n",
    "        missing_ema_idx.append(i)\n",
    "        missing_inchi_key.append(row.inchi_key)\n",
    "        \n",
    "print len(missing_ema_idx)\n",
    "ema_df = pd.read_pickle('/project/projectdirs/metatlas/projects/magi_paper/ema_neg_hilic_atlas_50447.pkl')\n",
    "\n",
    "for i,row in ema_df.iterrows():\n",
    "    if df_dedup[df_dedup.inchi_key == row.inchi_key].shape[0] == 0:\n",
    "        if not row.inchi_key in missing_inchi:\n",
    "            missing_ema_idx.append(i)\n",
    "            missing_inchi_key.append(row.inchi_key)\n",
    "        \n",
    "print len(missing_ema_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from metatlas import metatlas_objects as metob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inchis = []\n",
    "# for ik in missing_inchi_key:\n",
    "#     cpds = metob.retrieve('Compounds',inchi_key = ik,username='*')[-1]\n",
    "#     print cpds.name\n",
    "#     inchis.append(cpds.inchi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.unique(inchis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('/global/u2/b/bpb/Downloads/missing_ema_cpds.txt','w') as fid:\n",
    "#     fid.write('\\n'.join(pd.unique(inchis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "plt.hist(df_dedup.ms1_mass,bins = 50,range=(0,1200))\n",
    "plt.xlabel('molecular weight')\n",
    "plt.ylabel('# trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "plt.hist(df[df.ms1_mass > 0].ms1_mass,bins = 50,range=(0,1200))\n",
    "plt.xlabel('molecular weight')\n",
    "plt.ylabel('# trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "out = plt.hist(np.log10(df[df.time_to_build > 0].time_to_build/60),bins = 100)#,range=(0,1200))\n",
    "plt.xlabel('LOG10 time to build (minutes)')\n",
    "plt.ylabel('# trees')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "out = plt.plot(df.ms1_mass,df.time_to_build/60,'.')#,range=(0,1200))\n",
    "plt.ylabel('depth of 3\\ntime to build tree (min)')\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('molecular weight')\n",
    "plt.xlim(0,1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each row is a compound structure\n",
    "* inchi_key\n",
    "* is it in metatlas\n",
    "* is a tree made to a depth of 5\n",
    "* inchi_key has exact chembl preferred name & synonyms\n",
    "* inchi_key has exact pubchem synonyms\n",
    "* partial inchi_key has pubchem synonyms\n",
    "* is a job submitted to build the tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fields to add to metatlas db\n",
    "* path to tree file\n",
    "* prefered name from chembl\n",
    "* full inchikey synonyms from chembl\n",
    "* full inchikey synonyms from pubchem\n",
    "* partial inchikey synonyms from pubchem\n",
    "* partial inchikey pubchem cid\n",
    "* inchikey pubchem cid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit inchi list to nersc\n",
    "* trees that are not built need to be built\n",
    "* small trees are fast\n",
    "* large trees take 10 minutes to days\n",
    "* once they are built register their location in the database\n",
    "* some structures can't be built for various reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stop-gap plan\n",
    "* add location of tree to database\n",
    "* all trees must be in database\n",
    "* not all database compound have trees\n",
    "\n",
    "## store complete fragmentation of trees\n",
    "* store all unique fragments\n",
    "* store parent child relationship for each fragment\n",
    "* at some point generating fragment is faster than storing\n",
    "* only store immediate relationship between fragment\n",
    "* each fragment has an id\n",
    "* store a table linking parent and child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mass spec cori",
   "language": "python",
   "name": "mass_spec_cori"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
